\BOOKMARK [0][]{chapter.1}{1 绪论:初识机器学习}{}% 1
\BOOKMARK [1][]{section.1.1}{1.1 欢迎参加机器学习课程}{chapter.1}% 2
\BOOKMARK [1][]{section.1.2}{1.2 什么是机器学习}{chapter.1}% 3
\BOOKMARK [1][]{section.1.3}{1.3 监督学习}{chapter.1}% 4
\BOOKMARK [2][]{subsection.1.3.1}{1.3.1 回归问题}{section.1.3}% 5
\BOOKMARK [2][]{subsection.1.3.2}{1.3.2 分类问题}{section.1.3}% 6
\BOOKMARK [1][]{section.1.4}{1.4 无监督学习}{chapter.1}% 7
\BOOKMARK [1][]{section.1.5}{1.5 问题}{chapter.1}% 8
\BOOKMARK [0][]{chapter.2}{2 单变量线性回归}{}% 9
\BOOKMARK [1][]{section.2.1}{2.1 模型描述}{chapter.2}% 10
\BOOKMARK [1][]{section.2.2}{2.2 代价函数}{chapter.2}% 11
\BOOKMARK [1][]{section.2.3}{2.3 代价函数\(一\)}{chapter.2}% 12
\BOOKMARK [2][]{subsection.2.3.1}{2.3.1 编译方式}{section.2.3}% 13
\BOOKMARK [2][]{subsection.2.3.2}{2.3.2 选项设置}{section.2.3}% 14
\BOOKMARK [2][]{subsection.2.3.3}{2.3.3 数学环境简介}{section.2.3}% 15
\BOOKMARK [2][]{subsection.2.3.4}{2.3.4 可编辑的字段}{section.2.3}% 16
\BOOKMARK [1][]{section.2.4}{2.4 代价函数\(二\)}{chapter.2}% 17
\BOOKMARK [1][]{section.2.5}{2.5 梯度下降}{chapter.2}% 18
\BOOKMARK [1][]{section.2.6}{2.6 梯度下降知识点总结}{chapter.2}% 19
\BOOKMARK [1][]{section.2.7}{2.7 线性回归的梯度下降}{chapter.2}% 20
\BOOKMARK [1][]{section.2.8}{2.8 本章课程总结}{chapter.2}% 21
\BOOKMARK [0][]{chapter.3}{3 线性回归回顾}{}% 22
\BOOKMARK [1][]{section.3.1}{3.1 矩阵和向量}{chapter.3}% 23
\BOOKMARK [1][]{section.3.2}{3.2 加法和标量乘法}{chapter.3}% 24
\BOOKMARK [1][]{section.3.3}{3.3 矩阵向量乘法}{chapter.3}% 25
\BOOKMARK [1][]{section.3.4}{3.4 矩阵乘法}{chapter.3}% 26
\BOOKMARK [1][]{section.3.5}{3.5 矩阵乘法特征}{chapter.3}% 27
\BOOKMARK [1][]{section.3.6}{3.6 逆和转制}{chapter.3}% 28
\BOOKMARK [0][]{chapter.4}{4 配置}{}% 29
\BOOKMARK [1][]{section.4.1}{4.1 安装MTLAB并设置编程任务环境}{chapter.4}% 30
\BOOKMARK [1][]{section.4.2}{4.2 安装MATLAB}{chapter.4}% 31
\BOOKMARK [1][]{section.4.3}{4.3 在Windows上安装Octave}{chapter.4}% 32
\BOOKMARK [1][]{section.4.4}{4.4 在Mac OS X上安装Octave}{chapter.4}% 33
\BOOKMARK [1][]{section.4.5}{4.5 GNU/Linux上安装Octave}{chapter.4}% 34
\BOOKMARK [1][]{section.4.6}{4.6 更多Octave/MATLAB资源}{chapter.4}% 35
\BOOKMARK [0][]{chapter.5}{5 多变量线性回归}{}% 36
\BOOKMARK [1][]{section.5.1}{5.1 多功能}{chapter.5}% 37
\BOOKMARK [1][]{section.5.2}{5.2 多元梯度下降法}{chapter.5}% 38
\BOOKMARK [1][]{section.5.3}{5.3 多元梯度下降法演练I-特征缩放}{chapter.5}% 39
\BOOKMARK [1][]{section.5.4}{5.4 多元梯度下降法演练II-学习率}{chapter.5}% 40
\BOOKMARK [1][]{section.5.5}{5.5 特征和多项式回归}{chapter.5}% 41
\BOOKMARK [1][]{section.5.6}{5.6 正规方程\(区别于迭代方法的直接解决\)}{chapter.5}% 42
\BOOKMARK [1][]{section.5.7}{5.7 正规方程在矩阵不可逆情况下的解决方法}{chapter.5}% 43
\BOOKMARK [1][]{section.5.8}{5.8 完成并提交编程作业}{chapter.5}% 44
\BOOKMARK [0][]{chapter.6}{6 Octave/Matlab教程}{}% 45
\BOOKMARK [1][]{section.6.1}{6.1 基本操作}{chapter.6}% 46
\BOOKMARK [1][]{section.6.2}{6.2 移动数据}{chapter.6}% 47
\BOOKMARK [1][]{section.6.3}{6.3 计算数据}{chapter.6}% 48
\BOOKMARK [1][]{section.6.4}{6.4 数据绘制}{chapter.6}% 49
\BOOKMARK [1][]{section.6.5}{6.5 控制语句:for, while, if语句}{chapter.6}% 50
\BOOKMARK [1][]{section.6.6}{6.6 矢量}{chapter.6}% 51
\BOOKMARK [1][]{section.6.7}{6.7 本章课程总结}{chapter.6}% 52
\BOOKMARK [0][]{chapter.7}{7 Logistic回归}{}% 53
\BOOKMARK [1][]{section.7.1}{7.1 分类}{chapter.7}% 54
\BOOKMARK [1][]{section.7.2}{7.2 假设陈述}{chapter.7}% 55
\BOOKMARK [1][]{section.7.3}{7.3 决策界限}{chapter.7}% 56
\BOOKMARK [1][]{section.7.4}{7.4 代价函数}{chapter.7}% 57
\BOOKMARK [1][]{section.7.5}{7.5 简化代价函数与梯度下降}{chapter.7}% 58
\BOOKMARK [1][]{section.7.6}{7.6 高级优化}{chapter.7}% 59
\BOOKMARK [1][]{section.7.7}{7.7 多元分类:一对多}{chapter.7}% 60
\BOOKMARK [1][]{section.7.8}{7.8 本章课程总结}{chapter.7}% 61
\BOOKMARK [0][]{chapter.8}{8 正则化}{}% 62
\BOOKMARK [1][]{section.8.1}{8.1 过拟合问题}{chapter.8}% 63
\BOOKMARK [1][]{section.8.2}{8.2 代价函数}{chapter.8}% 64
\BOOKMARK [1][]{section.8.3}{8.3 线性回归的正则化}{chapter.8}% 65
\BOOKMARK [1][]{section.8.4}{8.4 Logistic回归的正则化}{chapter.8}% 66
\BOOKMARK [0][]{chapter*.14}{参考文献}{}% 67
